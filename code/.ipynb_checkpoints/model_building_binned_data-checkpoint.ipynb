{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "\n",
    "types = [('IC50',150), ('Ki',130), ('Kd',70)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(classifier, train_x, train_y, validate_x, validate_y, test_x, test_y):\n",
    "    classifier = classifier.fit(train_x, train_y)\n",
    "    scores = cross_val_score(estimator=classifier, X=validate_x, y=validate_y, cv=10)\n",
    "    print(\"Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "    y_pred = classifier.predict(test_x)\n",
    "    y_true = test_y.tolist()\n",
    "    \n",
    "    score = 0\n",
    "    for i in range(0,len(y_pred)):\n",
    "        if y_pred[i] == y_true[i]:\n",
    "            score += 1\n",
    "    score /= len(y_pred)\n",
    "    \n",
    "    print(\"Classifier Score: %0.2f\" % score)\n",
    "    print('Precision Score - micro : %0.2f' % precision_score(y_true, y_pred, average='micro'))\n",
    "    print('Recall Score - micro : %0.2f' % recall_score(y_true, y_pred, average='micro'))\n",
    "    print('F1 Score - micro : %0.2f' % f1_score(y_true, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type_ = types[0]\n",
    "x = type_[0]\n",
    "y = int(type_[1])\n",
    "print('-----', x, '-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/protLigBindDB_'+x+'_binned',skiprows=1)\n",
    "df = df.drop('PDB', 1)\n",
    "df = df.drop(x, 1)\n",
    "df = df.drop('log(' + x + ')', 1)\n",
    "df = df.drop('Log_Binned_Binding_Affinity', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, rest = train_test_split(df, test_size = 0.4)\n",
    "validate, test = train_test_split(rest, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_y = train[['Binned_Binding_Affinity']].as_matrix().flatten()\n",
    "train_x = train.drop('Binned_Binding_Affinity', 1).as_matrix()\n",
    "validate_y = validate[['Binned_Binding_Affinity']].as_matrix().flatten()\n",
    "validate_x = validate.drop('Binned_Binding_Affinity', 1).as_matrix()\n",
    "test_y = test[['Binned_Binding_Affinity']].as_matrix().flatten()\n",
    "test_x = test.drop('Binned_Binding_Affinity', 1).as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNeighborsClassifier\n",
    "Neighbors-based classification is a type of instance-based learning or non-generalizing learning: it does not attempt to construct a general internal model, but simply stores instances of the training data. Classification is computed from a simple majority vote of the nearest neighbors of each point: a query point is assigned the data class which has the most representatives within the nearest neighbors of the point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Nearest Neighbors\")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=10, weights='uniform', \n",
    "                                  algorithm='brute',  metric='minkowski', \n",
    "                                  p=2, n_jobs=1)\n",
    "classify(classifier=classifier, train_x=train_x, train_y=train_y, validate_x=validate_x, validate_y=validate_y, test_x=test_x, test_y=test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC\n",
    "The implementation is based on libsvm. The fit time complexity is more than quadratic with the number of samples which makes it hard to scale to dataset with more than a couple of 10000 samples.\n",
    "The multiclass support is handled according to a one-vs-one scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Linear SVM\")\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(C=1, kernel='linear', probability=False, \n",
    "                 shrinking=True, max_iter=-1)\n",
    "classify(classifier=classifier, train_x=train_x, train_y=train_y, validate_x=validate_x, validate_y=validate_y, test_x=test_x, test_y=test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"RBF SVM\")\n",
    "from sklearn.svm import SVC\n",
    "classifier = SVC(C=1, kernel='linear', probability=False, \n",
    "                 shrinking=True, max_iter=-1)\n",
    "classify(classifier=classifier, train_x=train_x, train_y=train_y, validate_x=validate_x, validate_y=validate_y, test_x=test_x, test_y=test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier\n",
    "A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and use averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement if bootstrap=True (default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Random Forest\")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=20, criterion='entropy', \n",
    "                                    max_features=None, max_depth=None, \n",
    "                                    min_samples_split=2, min_samples_leaf=1, \n",
    "                                    max_leaf_nodes=None, bootstrap=True)\n",
    "classify(classifier=classifier, train_x=train_x, train_y=train_y, validate_x=validate_x, validate_y=validate_y, test_x=test_x, test_y=test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLPClassifier\n",
    "Class MLPClassifier implements a multi-layer perceptron (MLP) algorithm that trains using Backpropagation.\n",
    "MLP trains on two arrays: array X of size (n_samples, n_features), which holds the training samples represented as floating point feature vectors; and array y of size (n_samples,), which holds the target values (class labels) for the training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Neural Net\")\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(100,), activation='logistic', \n",
    "                           solver='adam', max_iter=200, shuffle=True)\n",
    "classify(classifier=classifier, train_x=train_x, train_y=train_y, validate_x=validate_x, validate_y=validate_y, test_x=test_x, test_y=test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
